{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_sentiment_analysis_distillbert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount drive with the notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ojzXt-_6HZ",
        "outputId": "0217445d-ed0d-405d-d26b-b295e240fd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install required packages\n",
        "pip install transformers fast_ml"
      ],
      "metadata": {
        "id": "KD-ezkDd7atM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PyHyBojdDCp"
      },
      "outputs": [],
      "source": [
        "# import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataframe\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Vivek_Customer_Satisfaction/Twitter_Data.csv\")"
      ],
      "metadata": {
        "id": "KkRg6Huuelcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop if there any null values\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "tuH_GcKce9rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# {-1 -> Negative, 0 -> Neutral, 1 -> Positive}\n",
        "df['category'].value_counts()"
      ],
      "metadata": {
        "id": "x-GoVUF-fBhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clan messages\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^a-zA-Z0-9(+*) \\n\\.]', ' ', str(x)))\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub(\"\\s+\", \" \", str(x)))"
      ],
      "metadata": {
        "id": "CKYMg1SBfHxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replaces the lables classes \n",
        "df['category'] = df['category'].replace([1,-1,0],[0,1,2])"
      ],
      "metadata": {
        "id": "0ANnarwo-aqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train, valid, test\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target='category', \n",
        "                                                                            train_size=0.7, valid_size=0.2, test_size=0.1)"
      ],
      "metadata": {
        "id": "c33KdGDxqE89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convertiong dataframe into lists \n",
        "X_train = X_train['clean_text'].tolist()\n",
        "y_train = to_categorical(y_train)\n",
        "X_valid = X_valid['clean_text'].tolist()\n",
        "y_valid = to_categorical(y_valid)\n",
        "X_test = X_test['clean_text'].tolist()\n",
        "y_test = y_test.tolist() "
      ],
      "metadata": {
        "id": "ofp5JnSRCA49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define distilbert tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "mo0ToQnpH6LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define tokenize function that tokenize sentences and converting them into tensors\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=128, truncation=True, pad_to_max_length=True, return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ],
      "metadata": {
        "id": "DrfgTgeEO00p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the three datasets\n",
        "x_train = tokenize(X_train, tokenizer)\n",
        "x_valid = tokenize(X_valid, tokenizer)\n",
        "x_test = tokenize(X_test, tokenizer)"
      ],
      "metadata": {
        "id": "3jRpXMV1HuPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init distilbert model\n",
        "distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "zEJdqtPVI-1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids = x_train[0]\n",
        "train_attention_mask = x_train[1]"
      ],
      "metadata": {
        "id": "7BHtiDlYJMlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_input_ids = x_valid[0]\n",
        "valid_attention_mask = x_valid[1]"
      ],
      "metadata": {
        "id": "esLiji9EJWbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finetune the distilbert model by adding them layer\n",
        "max_len = 128\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = distilbert([input_ids,input_mask])[0] \n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(3,activation = 'sigmoid')(out)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ],
      "metadata": {
        "id": "g1iQYadBNmBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "optimizer = Adam(learning_rate=5e-05, decay=0.01)\n",
        "\n",
        "loss = CategoricalCrossentropy(from_logits = True)\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "XBj45RoaVjod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define callbacks \n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Vivek_Customer_Satisfaction/Model_Checkpoints/'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='/content/drive/MyDrive/Vivek_Customer_Satisfaction/Model_Checkpoints/logs', write_graph=True, write_images=False, update_freq='epoch')"
      ],
      "metadata": {
        "id": "UvipJsUBWKPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "train_history = model.fit(\n",
        "    x = [train_input_ids, train_attention_mask],\n",
        "    y = np.asarray(y_train),\n",
        "    validation_data = ([valid_input_ids, valid_attention_mask], np.asarray(y_valid)),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, checkpoint, tensorboard]\n",
        ")"
      ],
      "metadata": {
        "id": "PrkgTDtvYFb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664a42f0-5c4d-48d9-9ebb-f97db568938b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 545s 505ms/step - loss: 0.4058 - accuracy: 0.8481 - val_loss: 0.2359 - val_accuracy: 0.9214\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 529s 504ms/step - loss: 0.2190 - accuracy: 0.9309 - val_loss: 0.1941 - val_accuracy: 0.9388\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 530s 505ms/step - loss: 0.1828 - accuracy: 0.9428 - val_loss: 0.1769 - val_accuracy: 0.9439\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 530s 505ms/step - loss: 0.1615 - accuracy: 0.9499 - val_loss: 0.1668 - val_accuracy: 0.9472\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 568s 541ms/step - loss: 0.1491 - accuracy: 0.9532 - val_loss: 0.1650 - val_accuracy: 0.9481\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 530s 504ms/step - loss: 0.1399 - accuracy: 0.9569 - val_loss: 0.1603 - val_accuracy: 0.9501\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 568s 541ms/step - loss: 0.1337 - accuracy: 0.9592 - val_loss: 0.1529 - val_accuracy: 0.9525\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 530s 505ms/step - loss: 0.1282 - accuracy: 0.9609 - val_loss: 0.1520 - val_accuracy: 0.9531\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 567s 540ms/step - loss: 0.1246 - accuracy: 0.9621 - val_loss: 0.1500 - val_accuracy: 0.9536\n",
            "Epoch 10/10\n",
            "1050/1050 [==============================] - 529s 504ms/step - loss: 0.1210 - accuracy: 0.9633 - val_loss: 0.1471 - val_accuracy: 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model at specific path\n",
        "model.save('/content/drive/MyDrive/Vivek_Customer_Satisfaction/Model_Checkpoints/sentiment-analysis.h5')"
      ],
      "metadata": {
        "id": "wLz3SzylV-B0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}